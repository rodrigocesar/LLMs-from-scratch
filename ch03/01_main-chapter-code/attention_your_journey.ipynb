{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1307f8",
   "metadata": {},
   "source": [
    "\n",
    "# From Tokens → Embeddings → Attention (Q·K)  \n",
    "**Sentence:** *\"Your journey starts with one step.\"*\n",
    "\n",
    "This notebook quickly shows:\n",
    "1) **Tokenized corpus** vs **embeddings** (why we need vectors)  \n",
    "2) **Latent dimensions** intuition (toy semantic axes) + **similarity** (cosine & dot product)  \n",
    "3) **Self-attention** on the same sentence: Q, K, V → attention weights → context vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc401f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30830143",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Tokenized Corpus vs Embeddings\n",
    "\n",
    "- **Tokenized corpus**: a sequence of discrete symbols (tokens/IDs).  \n",
    "- **Embeddings**: continuous vectors that *compress* token meaning into numbers (latent features).\n",
    "\n",
    "We'll use the sentence used in the book: **\"Your journey starts with one step.\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a833188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenization\n",
    "sentence = \"Your journey starts with one step.\"\n",
    "tokens = [t.strip(\".,!?\").lower() for t in sentence.split()]\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ac9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build tiny vocab from the sentence\n",
    "special = [\"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "word_set = special + sorted(set(tokens))\n",
    "vocab = {w:i for i,w in enumerate(word_set)}\n",
    "ivocab = {i:w for w,i in vocab.items()}\n",
    "\n",
    "def encode(ws):\n",
    "    return torch.tensor([vocab[\"<bos>\"]] + [vocab[w] for w in ws] + [vocab[\"<eos>\"]], dtype=torch.long)\n",
    "\n",
    "ids = encode(tokens)\n",
    "print(\"Vocab:\", vocab)\n",
    "print(\"Token IDs:\", ids.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d2469a",
   "metadata": {},
   "source": [
    "\n",
    "**Takeaway:** token IDs are **discrete**; neural nets need **vectors** to compute.  \n",
    "Next, we embed each token ID into a **dense vector**. We'll use 3D to keep things readable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c2e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3D embeddings + fixed values for the six words\n",
    "emb_dim = 3\n",
    "emb = nn.Embedding(len(vocab), emb_dim)\n",
    "\n",
    "with torch.no_grad():\n",
    "    emb.weight.zero_()\n",
    "    emb.weight[vocab[\"your\"]]    = torch.tensor([0.43, 0.15, 0.89])\n",
    "    emb.weight[vocab[\"journey\"]] = torch.tensor([0.55, 0.87, 0.66])\n",
    "    emb.weight[vocab[\"starts\"]]  = torch.tensor([0.57, 0.85, 0.64])\n",
    "    emb.weight[vocab[\"with\"]]    = torch.tensor([0.22, 0.58, 0.33])\n",
    "    emb.weight[vocab[\"one\"]]     = torch.tensor([0.77, 0.25, 0.10])\n",
    "    emb.weight[vocab[\"step\"]]    = torch.tensor([0.05, 0.80, 0.55])\n",
    "\n",
    "X_tokens = torch.stack([emb.weight[vocab[w]] for w in tokens], dim=0)\n",
    "print(\"Token embeddings (3D) for the 6 words:\\n\", X_tokens)\n",
    "print(\"Shape:\", X_tokens.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec45d2c",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Latent Dimensions & Similarity (Cosine / Dot)\n",
    "\n",
    "An embedding dimension can be interpreted as a **latent feature**.  \n",
    "For intuition, imagine toy axes like:\n",
    "- dim0: \"is_movement\"  \n",
    "- dim1: \"is_abstract\"  \n",
    "- dim2: \"is_objectness\"\n",
    "\n",
    "> These are made-up for teaching; real models learn their own axes.\n",
    "\n",
    "We measure **similarity** with **cosine** or **dot product**.  \n",
    "The attention score uses a **dot product** (scaled) between **Q** and **K**, which is like asking:  \n",
    "> *Do my interests (Q) align with your attributes (K)?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c97504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine(a,b, dim=-1, eps=1e-8):\n",
    "    an = a / (a.norm(dim=dim, keepdim=True)+eps)\n",
    "    bn = b / (b.norm(dim=dim, keepdim=True)+eps)\n",
    "    return (an*bn).sum(dim=dim)\n",
    "\n",
    "pairs = [(\"journey\",\"starts\"), (\"one\",\"step\"), (\"your\",\"journey\"), (\"with\",\"your\")]\n",
    "for a,b in pairs:\n",
    "    va, vb = emb.weight[vocab[a]], emb.weight[vocab[b]]\n",
    "    cos = float(cosine(va, vb))\n",
    "    dot = float(va @ vb)\n",
    "    print(f\"{a:>7s} vs {b:<7s}  cosine={cos:.3f}  dot={dot:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0029c",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Add Positional Embeddings\n",
    "\n",
    "Self-attention alone has no sense of order, so we add positional vectors and sum with token embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c94c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos_emb = nn.Embedding(16, 3)\n",
    "with torch.no_grad():\n",
    "    pos_emb.weight.copy_(torch.tensor([\n",
    "        [0.00, 0.00, 0.00],\n",
    "        [0.01, 0.02, 0.03],\n",
    "        [0.02, 0.01, -0.01],\n",
    "        [0.03, 0.00, 0.01],\n",
    "        [0.04, -0.01, 0.02],\n",
    "        [0.05, 0.02, 0.00],\n",
    "        [0.06, 0.03, -0.02],\n",
    "        [0.07, 0.01, 0.01],\n",
    "        [0.08, 0.00, -0.01],\n",
    "        [0.09, -0.02, 0.02],\n",
    "        [0.10, 0.03, 0.00],\n",
    "        [0.11, 0.00, 0.01],\n",
    "        [0.12, 0.01, -0.02],\n",
    "        [0.13, -0.01, 0.02],\n",
    "        [0.14, 0.02, 0.00],\n",
    "        [0.15, 0.01, 0.01],\n",
    "    ], dtype=torch.float))\n",
    "\n",
    "pos = torch.arange(len(tokens))\n",
    "X = X_tokens + pos_emb(pos)\n",
    "print(\"X = token + positional embeddings:\\n\", X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2ba9c1",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Attention on the Sentence (Single Head)\n",
    "\n",
    "We compute **Q**, **K**, **V**, then:\n",
    "\\[\n",
    "\\text{scores} = \\frac{QK^\\top}{\\sqrt{d_k}}, \\quad\n",
    "\\text{weights} = \\text{softmax}(\\text{scores}), \\quad\n",
    "Z = \\text{weights}\\cdot V\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "head_dim = 2\n",
    "W_Q = nn.Linear(3, head_dim, bias=False)\n",
    "W_K = nn.Linear(3, head_dim, bias=False)\n",
    "W_V = nn.Linear(3, head_dim, bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    W_Q.weight.copy_(torch.tensor([[0.5, 0.0, 0.5],\n",
    "                                   [0.0, 0.5, -0.5]]))\n",
    "    W_K.weight.copy_(torch.tensor([[0.4, -0.1, 0.3],\n",
    "                                   [-0.2, 0.6, 0.1]]))\n",
    "    W_V.weight.copy_(torch.tensor([[0.3, 0.1, -0.2],\n",
    "                                   [0.1, -0.3, 0.4]]))\n",
    "\n",
    "Q, K, V = W_Q(X), W_K(X), W_V(X)\n",
    "scores = (Q @ K.T) / math.sqrt(head_dim)\n",
    "weights = torch.softmax(scores, dim=-1)\n",
    "Z = weights @ V\n",
    "\n",
    "print(\"Q:\\n\", Q, \"\\n\")\n",
    "print(\"K:\\n\", K, \"\\n\")\n",
    "print(\"V:\\n\", V, \"\\n\")\n",
    "print(\"Scores (scaled QK^T):\\n\", scores, \"\\n\")\n",
    "print(\"Attention weights (rows sum to 1):\\n\", weights, \"\\n\")\n",
    "print(\"Context vectors Z:\\n\", Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b70a5",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Wrap-up\n",
    "\n",
    "- **Tokenized corpus**: discrete IDs for words/subwords.  \n",
    "- **Embeddings**: continuous vectors where dimensions act as **latent features**.  \n",
    "- **Similarity** via cosine/dot reflects **alignment** of features.  \n",
    "- **Attention** uses the dot product of \\(Q\\) and \\(K\\) so each token “listens” to the most relevant others; \n",
    "  the resulting **context vector \\(Z\\)** is a **weighted mixture** of **V** across the sentence.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
